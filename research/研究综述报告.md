# 刘睿 2026/1/9 

## 文献调研综述 

### 1. [A Survey of Large Language Models in Finance (FinLLMs)](https://arxiv.org/abs/2402.02315)

本文是一篇关于 FinLLMs 的系统性综述，介绍了近年来的技术演进，模型对比与未来的方向。其中第六部分的 **Opportunities and Challenges** 从 Datasets，Techniques，Evaluation，Implementation，Application 五个方面梳理了当前 FinLLMs 面临的问题与发展方向 

其中提到了两个比较关键的内容 **instruction fine-tuned financial datasets** 和 **Retrieval Augmented Generation（RAG）**，代表了本次毕设可以追求的两种方向。一种是去对大模型进行训练和微调，使其满足个股推荐任务的需求；另一种是通过通用LLM + Prompting + RAG，依靠现有大模型的自然语言能力进行生成 

我的毕设更接近于 **通用LLM + Prompting + RAG** 这么一个路线，后面会提到的同花顺问财AI和东方财富妙想大模型应该也主要是基于这一种实现方式

此外，文中提到了如今 FinLLMs 当前的评估过度依赖通用NLP的指标，而非更加专业的金融指标（如夏普率和回测收益等），也缺少金融专家参与评估。我的毕设理论上来说也应该是通过专业金融指标来评估，同时可以引入学生代替金融专家的身份进行评估

### 2. [Evaluation of Retrieval-Augmented Generation](https://arxiv.org/pdf/2405.07437)

本文主要介绍了如何对 RAG 进行评估，提出了 **Auepora三问**，即 

> - What to Evaluate
> - How to Evaluate
> - How to Measure

本篇内容在当前阶段并不是非常关键，但考虑到之后应该会采取 RAG 的方法，本篇中提到的各种评估手段会是之后任务的重要内容 

## 产品调研综述 

### 1. 同花顺问财

从我的使用体验来看，问财属于比较典型的 Agentic RAG + 工具调用链 思路：模型会通过多轮工具/接口调用去获取行情、公告、新闻、研报等信息，并将结果整合成回答。整体优势是数据与可视化呈现较强（例如能同时展示 K 线、关键指标等），且面向用户的交互链路较完整

### 2. 东方财富妙想

妙想同样属于“检索增强 + 金融数据支撑 + 语言生成”的产品形态，整体表达更偏专业化，并且在“深度检索”层面覆盖的资料较广（公告、行业报告、研究员内容等）。从定位上看，它更像一个“AI 投研/投资助理”的入口

放在一起对比，优缺点如下：

优点在于

1. 产品化完成度高，回答中嵌入图表/行情组件等，体验接近“可用工具”而非单纯聊天
2. 数据底座强，结构化数据（行情/指标）与非结构化语料（公告/研报/新闻）覆盖面广
3. 非结构化检索深，能把大量信息一次性组织出来，适合“快速概览” 

问题在于

1. **更像 “搜索+拼装” 而非 “可验证推理”**，很多时候系统在堆叠信息，但结论与证据之间的“推理链”并不清晰，用户很难判断每个结论的依据强弱
2. 工程链路不稳定的外显，在复杂问题上容易暴露工具调用失败或中间格式输出（这会直接影响用户信任）
2. 脱离量化，即使会提到“预测/量化模型”，也不一定能稳定给出明确的结构化输出（如信号、区间胜率、回测摘要），导致解释容易漂浮在文本层面，甚至会出现显示“正在搜索相关量化模型预测”但最后并未得到结果

## 总结 

经过文献与产品调研，我认为我可以把毕设重点更明确地落在两条主线上：

**1) 以量化为主的“解释型个股解读”**

问财与妙想在自然语言解释和信息检索上很强，但量化结果往往没有成为“主证据”。我更希望反过来：

先由量化模块给出结构化结论（信号/风险/回测片段/关键因子贡献）

再由大模型在证据约束下做解释、整合事件与背景信息
也就是说：让 LLM 更像“解释器/报告生成器”，而不是“结论来源”。

**2) 强化忠实度与可核验性：让解释“对得上证据”**

把评估重点放在 忠实度（faithfulness）与证据可核验（verifiability） 上，具体体现为：

解释必须与 XAI 的归因方向一致（不把次要因子说成主因）

关键结论必须能追溯到 RAG 检索证据或结构化量化输出

当证据不足时，系统要能降级/拒答，而不是“硬编一个确定结论”




